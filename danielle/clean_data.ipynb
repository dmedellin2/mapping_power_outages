{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Word2Vec](https://pathmind.com/wiki/word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>search_term</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>radius</th>\n",
       "      <th>query_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>710245730590404608</td>\n",
       "      <td>TTWN SF Bay Area</td>\n",
       "      <td>Power outage in Cupertino #BayArea #Traffic ht...</td>\n",
       "      <td>2016-03-16 23:25:52</td>\n",
       "      <td>power outage</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>37.3323</td>\n",
       "      <td>-121.853394</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>708811502241734656</td>\n",
       "      <td>San Jose Now</td>\n",
       "      <td>WEATHER ALERT: Flash flood watch in Bay Area a...</td>\n",
       "      <td>2016-03-13 00:26:45</td>\n",
       "      <td>power outage</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>37.3323</td>\n",
       "      <td>-121.853394</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>706856719733776384</td>\n",
       "      <td>San Jose Now</td>\n",
       "      <td>Power outages:30 in San Francisco154 on Penins...</td>\n",
       "      <td>2016-03-07 14:59:09</td>\n",
       "      <td>power outage</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>37.3323</td>\n",
       "      <td>-121.853394</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>726876023573204993</td>\n",
       "      <td>San Jose Now</td>\n",
       "      <td>Power outage in Fremont. Several intersections...</td>\n",
       "      <td>2016-05-01 20:48:43</td>\n",
       "      <td>power outage</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>37.3323</td>\n",
       "      <td>-121.853394</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>724681945095888897</td>\n",
       "      <td>San Jose Now</td>\n",
       "      <td>East Bay power outages also affects BART, UC B...</td>\n",
       "      <td>2016-04-25 19:30:14</td>\n",
       "      <td>power outage</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>37.3323</td>\n",
       "      <td>-121.853394</td>\n",
       "      <td>10mi</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id          username  \\\n",
       "0  710245730590404608  TTWN SF Bay Area   \n",
       "1  708811502241734656      San Jose Now   \n",
       "2  706856719733776384      San Jose Now   \n",
       "3  726876023573204993      San Jose Now   \n",
       "4  724681945095888897      San Jose Now   \n",
       "\n",
       "                                                text           tweet_date  \\\n",
       "0  Power outage in Cupertino #BayArea #Traffic ht...  2016-03-16 23:25:52   \n",
       "1  WEATHER ALERT: Flash flood watch in Bay Area a...  2016-03-13 00:26:45   \n",
       "2  Power outages:30 in San Francisco154 on Penins...  2016-03-07 14:59:09   \n",
       "3  Power outage in Fremont. Several intersections...  2016-05-01 20:48:43   \n",
       "4  East Bay power outages also affects BART, UC B...  2016-04-25 19:30:14   \n",
       "\n",
       "    search_term      city      lat        long radius query_start  \n",
       "0  power outage  San Jose  37.3323 -121.853394   10mi  2016-01-01  \n",
       "1  power outage  San Jose  37.3323 -121.853394   10mi  2016-01-01  \n",
       "2  power outage  San Jose  37.3323 -121.853394   10mi  2016-01-01  \n",
       "3  power outage  San Jose  37.3323 -121.853394   10mi  2016-01-01  \n",
       "4  power outage  San Jose  37.3323 -121.853394   10mi  2016-01-01  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "cali = pd.read_csv('../data/scrape_dm_cali.csv')\n",
    "\n",
    "mich = pd.read_csv('../data/scrape_dm_mich.csv')\n",
    "\n",
    "ny = pd.read_csv('../data/scrape_dm_ny.csv')\n",
    "\n",
    "ohio = pd.read_csv('../data/scrape_dm_ohio.csv')\n",
    "\n",
    "texas = pd.read_csv('../data/scrape_dm_texas.csv')\n",
    "\n",
    "tweets = pd.concat([cali, mich, ny, ohio, texas])\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20100, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16913, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.reset_index(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index          0\n",
       "tweet_id       0\n",
       "username       0\n",
       "text           0\n",
       "tweet_date     0\n",
       "search_term    0\n",
       "city           0\n",
       "lat            0\n",
       "long           0\n",
       "radius         0\n",
       "query_start    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to clean tweets & usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    string = string.lower()\n",
    "    url_pattern = r'((http|ftp|https):\\/\\/)?[\\w\\-_]+(\\.[\\w\\-_]+)+([\\w\\-\\.,@?^=%&amp;:/~\\+#]*[\\w\\-\\@?^=%&amp;/~\\+#])?'\n",
    "    string = re.sub(url_pattern, ' ', string)\n",
    "    string = re.sub(r\"\\n\", \"\", string)    \n",
    "    string = re.sub(r\"\\r\", \"\", string) \n",
    "    string = re.sub(r\"[0-9]+\", \"\", string)\n",
    "    string = re.sub(r'[^\\w\\s]','', string)    \n",
    "    \n",
    "    return string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['text'] = tweets['text'].map(clean_str)\n",
    "tweets['username'] = tweets['username'].map(clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making new column with username + tweet\n",
    "tweets['name_and_tweet'] = tweets['username'] + \" \" +tweets['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Word2Vec\n",
    "from gensim.models.word2vec import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning cleaned tweets into list of lists\n",
    "\n",
    "def tweet_to_words(tweets):\n",
    "    # empty list of tweets\n",
    "    list_of_tweets = []\n",
    "    \n",
    "    # make tweet into list of words\n",
    "    for tweet in tweets:\n",
    "        tweet = tweet.split()\n",
    "    \n",
    "        # list of stop words\n",
    "        stops = ['los','angeles','san','diego','jose','columbus','cleveland',\n",
    "             'cincinatti','detroit','ann','arbor','warren','new','york',\n",
    "             'ny','buffalo','rochester','michigan','california','ohio','texas',\n",
    "            'st','amc','scott','schudlich','finnished','de','antonio','la','houston',\n",
    "                 'dallas', 'santa', 'ana', 'clara', 'grand', 'rapids', 'kearny','mesa',\n",
    "                'peticolas','christmas']\n",
    "    \n",
    "        # Remove stopwords.\n",
    "        meaningful_tweet = [w for w in tweet if not w in stops]\n",
    "    \n",
    "        # add tweet to big list\n",
    "        list_of_tweets.append(meaningful_tweet)\n",
    "\n",
    "    return list_of_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making corpus\n",
    "corpus = tweet_to_words(tweets['name_and_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Train a model! \n",
    "model = Word2Vec(corpus,      # Corpus of data.\n",
    "                  size=100,    # How many dimensions do you want in your word vector?\n",
    "                  window=5,    # How many \"context words\" do you want?\n",
    "                  min_count=1, # Ignores words below this threshold.\n",
    "                  sg=1,        # SG = 1 uses SkipGram, SG = 0 uses CBOW (default).\n",
    "                  workers=4)   # Number of \"worker threads\" to use (parallelizes process).\n",
    "\n",
    "# # Do what you'd like to do with your data!\n",
    "# model.most_similar(\"car\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing out words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('aep', 0.9570109844207764),\n",
       " ('currently', 0.9534438848495483),\n",
       " ('reported', 0.9530239105224609),\n",
       " ('update', 0.9519146680831909),\n",
       " ('widespread', 0.950791597366333),\n",
       " ('wind', 0.9502784013748169),\n",
       " ('planned', 0.9488312602043152),\n",
       " ('experiencing', 0.9479764699935913),\n",
       " ('affecting', 0.9418179392814636),\n",
       " ('news', 0.9389858841896057)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('dte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('customers', 0.8877463340759277),\n",
       " ('crews', 0.8768340349197388),\n",
       " ('without', 0.8660569190979004),\n",
       " ('lines', 0.8516985774040222),\n",
       " ('affecting', 0.8510775566101074),\n",
       " ('experiencing', 0.8509665727615356),\n",
       " ('restoration', 0.8467317223548889),\n",
       " ('county', 0.8454038500785828),\n",
       " ('reports', 0.8447811603546143),\n",
       " ('area', 0.8438729047775269)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('outages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('light', 0.6927928924560547),\n",
       " ('music', 0.6893447637557983),\n",
       " ('hanging', 0.683314323425293),\n",
       " ('totally', 0.6826909780502319),\n",
       " ('tonight', 0.6807053089141846),\n",
       " ('checking', 0.6710796356201172),\n",
       " ('bar', 0.6680662631988525),\n",
       " ('georgia', 0.6608129143714905),\n",
       " ('friday', 0.6594502329826355),\n",
       " ('playing', 0.6566678285598755)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('lights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to check for words in tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweets['name_and_tweet']:\n",
    "    if 'insertwordhere' in tweet:\n",
    "        print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
